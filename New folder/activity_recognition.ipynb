{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1fe6a0",
   "metadata": {},
   "source": [
    "#### Imports Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53536412",
   "metadata": {
    "papermill": {
     "duration": 3.427823,
     "end_time": "2022-07-26T08:40:40.880880",
     "exception": false,
     "start_time": "2022-07-26T08:40:37.453057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -- IMPORTS START --\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "# -- IMPORTS END --\n",
    "\n",
    "# enable zooming into graphs\n",
    "%matplotlib widget\n",
    "plt.rcParams['figure.figsize'] = [9, 6] # width, height in inches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176444cb",
   "metadata": {},
   "source": [
    "### Helper Function: viz_tree (do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ffb5eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to visualize model - Do not modify\n",
    "def viz_tree(dt_model,features_frames,cnames):\n",
    "    # Fix feature names as list\n",
    "    feature_names = features_frames.columns.tolist()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9,4))\n",
    "    tree.plot_tree(dt_model,  \n",
    "                   feature_names=feature_names,\n",
    "                   fontsize=7,\n",
    "                   class_names=cnames,\n",
    "                   filled=True,\n",
    "                   ax=ax)\n",
    "\n",
    "    plt.title('Decision Tree')\n",
    "    plt.savefig('dt.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0fd91",
   "metadata": {},
   "source": [
    "### Helper Function: calc_magnitude (do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26629e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "def calc_magnitude(data):\n",
    "\n",
    "    # Calculate magnitude  \n",
    "    data['accel_mag'] = np.sqrt(data['x']**2 + data['y']**2 + data['z']**2) # absolute accel magnitude\n",
    "    data['accel_mag'] = data['accel_mag'] - data['accel_mag'].mean() # detrend: \"remove gravity\"\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c396d9",
   "metadata": {},
   "source": [
    "### Helper Function: remove noise (do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69e662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "def remove_noise(data,sampling_rate):\n",
    "    from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "    # Low pass filter\n",
    "    cutoff = 5 # Hz\n",
    "    order = 2\n",
    "    b, a = butter(order, cutoff/(sampling_rate/2), btype='lowpass')\n",
    "    data['filtered_accel_mag'] = filtfilt(b, a, data['accel_mag'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc1443",
   "metadata": {},
   "source": [
    "### Helper Function: add_features (do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa7fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "def add_features(window: pd.DataFrame):\n",
    "    features = {}\n",
    "    features['avg'] = window['accel_mag'].mean()\n",
    "    features['max'] = window['accel_mag'].quantile(1)\n",
    "    features['med'] = window['accel_mag'].quantile(0.5)\n",
    "    features['min'] = window['accel_mag'].quantile(0)\n",
    "    features['q25'] = window['accel_mag'].quantile(0.25)\n",
    "    features['q75'] = window['accel_mag'].quantile(0.75)\n",
    "    features['std'] = window['accel_mag'].std()\n",
    "    # df = pd.DataFrame()\n",
    "    # df = df.append(features,ignore_index=True)\n",
    "    df = pd.DataFrame([features])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679dc62",
   "metadata": {},
   "source": [
    "### Helper Function: train_decision_tree (do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66551f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(frames):\n",
    "    # Extract feature columns \n",
    "    X = frames[['avg', 'max', 'med', 'min', 'q25', 'q75', 'std']]\n",
    "\n",
    "    # Extract target column\n",
    "    y = frames['activity']\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "\n",
    "    # Create model\n",
    "    dt_model = DecisionTreeClassifier(criterion='entropy',max_depth=5).fit(X_train, y_train)\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    return dt_model,dt_cm,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a44b3",
   "metadata": {},
   "source": [
    "### Helper Function: classify_live_window (do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "428f5643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_live_window(df):\n",
    "    \n",
    "    # Filter accelerometer data \n",
    "    df_accel = df[df['accel_x'].notna() & df['accel_y'].notna() & df['accel_z'].notna()]\n",
    "    df_valid = df_accel[['accel_x', 'accel_y', 'accel_z']].rename(columns={\n",
    "      'accel_x': 'x',\n",
    "      'accel_y': 'y',\n",
    "      'accel_z': 'z'  \n",
    "    })\n",
    "\n",
    "    # Calculate accel_mag\n",
    "    df_valid = calc_magnitude(df_valid) \n",
    "\n",
    "    # Add features\n",
    "    df_valid = add_features(df_valid) \n",
    "    X = df_valid[['avg', 'max', 'med', 'min', 'q25', 'q75',  'std']] \n",
    "\n",
    "    # Load model\n",
    "    with open('dt_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "        \n",
    "    # Make prediction\n",
    "    y_pred = model.predict(df_valid)\n",
    "\n",
    "    return(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4038ab9",
   "metadata": {},
   "source": [
    "### Testing the live model (do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55e19f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_live_classification(): # Testing the live model\n",
    "    # Generate sample DataFrame\n",
    "    data = {'accel_x': [0.011531], \n",
    "            'accel_y': [0.002931],\n",
    "            'accel_z': [0.019604],\n",
    "            'time': ['2023-08-01 18:40:43.344408']}\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Repeat rows to get 1000 rows\n",
    "    df = pd.concat([df]*1000, ignore_index=True) \n",
    "\n",
    "    # Call function\n",
    "    y_pred = classify_live_window(df)\n",
    "\n",
    "    print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a54fb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract windows and features\n",
    "def extract_features(data, window_sec, sample_rate, activity):\n",
    "    # TODO - see instructions above\n",
    "    window_data = data.resample(str(window_sec) + \"S\")\n",
    "\n",
    "    dataFrameToReturn = pd.DataFrame(\n",
    "        columns=[\"avg\", \"max\", \"med\", \"min\", \"q25\", \"q75\", \"std\", \"label\"],\n",
    "    )\n",
    "\n",
    "    for time, window in window_data:\n",
    "        features = add_features(window)\n",
    "        features[\"label\"] = [activity]\n",
    "        dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
    "\n",
    "    return dataFrameToReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc737c7e",
   "metadata": {
    "papermill": {
     "duration": 0.251452,
     "end_time": "2022-07-26T08:40:41.158659",
     "exception": false,
     "start_time": "2022-07-26T08:40:40.907207",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def all_data_to_combined_csv():\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    folders = glob.glob(\"data/Activities/*\")[1:]\n",
    "    all_data = pd.DataFrame(\n",
    "        columns=[\"avg\", \"max\", \"med\", \"min\", \"q25\", \"q75\", \"std\", \"label\"],\n",
    "    )\n",
    "\n",
    "    all_data_list = []\n",
    "\n",
    "    for folder in folders:\n",
    "        activity = os.path.basename(folder)\n",
    "        file_names = glob.glob(\"data/Activities/\" + activity + \"/*.csv\")\n",
    "\n",
    "        for file in file_names:\n",
    "            file_data = pd.read_csv(file, parse_dates=[\"time\"], index_col=\"time\")\n",
    "\n",
    "            window_sec = 10\n",
    "            sampling_rate = 100\n",
    "\n",
    "            file_data = calc_magnitude(file_data)\n",
    "            file_data = remove_noise(file_data, sampling_rate)\n",
    "            file_data = extract_features(file_data, window_sec, sampling_rate, activity)\n",
    "\n",
    "            all_data_list.append(file_data)\n",
    "\n",
    "    all_data = pd.concat(all_data_list, join=\"outer\")\n",
    "\n",
    "    all_data.to_csv(\n",
    "        \"./data/Activities/all_data.csv\",\n",
    "        columns=[\"avg\", \"max\", \"med\", \"min\", \"q25\", \"q75\", \"std\", \"label\"],\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa40e93",
   "metadata": {},
   "source": [
    "# Experimenting with Different Activity Combinations\n",
    "\n",
    "| Model trained on | Accuracy |\n",
    "|-|-|\n",
    "| Three Types of Walking | 0.7056 |\n",
    "| Stairs Activities | 0.8846 | \n",
    "| Static Activities | 0.6253 |\n",
    "| Mobile Activities | 0.6026 |\n",
    "| All Activities | 0.6483 |\n",
    "|-|-|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0c2bf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n",
      "C:\\Users\\artif\\AppData\\Local\\Temp\\ipykernel_11772\\1764860010.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrameToReturn = pd.concat([dataFrameToReturn, features], join=\"inner\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['walk_fast', 'walk_mod', 'walk_slow']\n",
      "Accuracy:  0.7058823529411765 \n",
      " Precision:  [0.84  0.575 0.8  ] \n",
      " Recall:  [0.67741935 0.82142857 0.61538462]\n",
      "Confusion Matrix: \n",
      " [[21  9  1]\n",
      " [ 2 23  3]\n",
      " [ 2  8 16]]\n",
      "['downstairs', 'upstairs']\n",
      "Accuracy:  0.8846153846153846 \n",
      " Precision:  [0.85714286 0.91666667] \n",
      " Recall:  [0.92307692 0.84615385]\n",
      "Confusion Matrix: \n",
      " [[12  1]\n",
      " [ 2 11]]\n",
      "['lying', 'sitting', 'standing']\n",
      "Accuracy:  0.6823529411764706 \n",
      " Precision:  [0.69230769 0.7        0.65517241] \n",
      " Recall:  [0.5625     0.77777778 0.73076923]\n",
      "Confusion Matrix: \n",
      " [[18  6  8]\n",
      " [ 4 21  2]\n",
      " [ 4  3 19]]\n",
      "['downstairs', 'jogging', 'upstairs', 'walk_fast', 'walk_mod', 'walk_slow']\n",
      "Accuracy:  0.5960264900662252 \n",
      " Precision:  [0.39130435 0.94444444 0.         0.45833333 0.37037037 0.7027027 ] \n",
      " Recall:  [0.52941176 0.89473684 0.         0.47826087 0.37037037 0.78787879]\n",
      "Confusion Matrix: \n",
      " [[ 9  0  3  4  1  0]\n",
      " [ 1 34  0  3  0  0]\n",
      " [ 0  0  0  3  9  1]\n",
      " [ 5  2  0 11  4  1]\n",
      " [ 6  0  1  1 10  9]\n",
      " [ 2  0  0  2  3 26]]\n",
      "['downstairs', 'jogging', 'lying', 'sitting', 'standing', 'upstairs', 'walk_fast', 'walk_mod', 'walk_slow']\n",
      "Accuracy:  0.6483050847457628 \n",
      " Precision:  [0.5625     0.86956522 0.68       0.71428571 0.7        0.\n",
      " 0.41666667 0.4375     0.75      ] \n",
      " Recall:  [0.81818182 0.93023256 0.56666667 0.78125    0.7        0.\n",
      " 0.51724138 0.56       0.48      ]\n",
      "Confusion Matrix: \n",
      " [[ 9  0  0  0  0  0  1  1  0]\n",
      " [ 0 40  0  0  0  0  3  0  0]\n",
      " [ 0  0 17  6  5  0  1  0  1]\n",
      " [ 0  0  4 25  3  0  0  0  0]\n",
      " [ 0  0  3  4 21  0  0  0  2]\n",
      " [ 0  0  0  0  0  0  8  3  0]\n",
      " [ 3  6  1  0  0  0 15  4  0]\n",
      " [ 3  0  0  0  0  0  7 14  1]\n",
      " [ 1  0  0  0  1  0  1 10 12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artif\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_data_to_combined_csv()\n",
    "\n",
    "feature_frames = pd.read_csv(\"data/Activities/all_data.csv\")\n",
    "\n",
    "# ['downstairs','jogging','lying','sitting','standing','upstairs','walk_fast','walk_mod','walk_slow']\n",
    "# drop_activities = ['downstairs','jogging','lying','sitting','standing','upstairs']\n",
    "# drop_activities = ['jogging','lying','sitting','standing','walk_fast','walk_mod','walk_slow']\n",
    "# drop_activities = ['downstairs','jogging','upstairs','walk_fast','walk_mod','walk_slow']\n",
    "# drop_activities = ['lying','sitting','standing']\n",
    "# drop_activities = []\n",
    "\n",
    "drop_activities_list = [\n",
    "    [\"downstairs\", \"jogging\", \"lying\", \"sitting\", \"standing\", \"upstairs\"],\n",
    "    [\"jogging\", \"lying\", \"sitting\", \"standing\", \"walk_fast\", \"walk_mod\", \"walk_slow\"],\n",
    "    [\"downstairs\", \"jogging\", \"upstairs\", \"walk_fast\", \"walk_mod\", \"walk_slow\"],\n",
    "    [\"lying\", \"sitting\", \"standing\"],\n",
    "    []\n",
    "]\n",
    "\n",
    "all_activities = [\n",
    "    \"downstairs\",\n",
    "    \"jogging\",\n",
    "    \"lying\",\n",
    "    \"sitting\",\n",
    "    \"standing\",\n",
    "    \"upstairs\",\n",
    "    \"walk_fast\",\n",
    "    \"walk_mod\",\n",
    "    \"walk_slow\",\n",
    "]\n",
    "\n",
    "feature_names = [\n",
    "    \"avg\",\n",
    "    \"max\",\n",
    "    \"med\",\n",
    "    \"min\",\n",
    "    \"q25\",\n",
    "    \"q75\",\n",
    "    \"std\",\n",
    "]\n",
    "\n",
    "for drop_activities in drop_activities_list:\n",
    "    used_activities = []\n",
    "    for act in all_activities:\n",
    "        if act not in drop_activities:\n",
    "            used_activities.append(act)\n",
    "\n",
    "    print(used_activities)\n",
    "\n",
    "    masked_feature_frames = pd.read_csv(\"data/Activities/all_data.csv\")\n",
    "\n",
    "    for index, row in masked_feature_frames.iterrows():\n",
    "        if row[\"label\"] in drop_activities:\n",
    "            masked_feature_frames.drop(index=index, inplace=True)\n",
    "\n",
    "    # This function will print out precision/recall/accuracy\n",
    "    features = masked_feature_frames[feature_names]\n",
    "    labels = masked_feature_frames[\"label\"]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "    dt_model = DecisionTreeClassifier(max_depth=5, criterion=\"entropy\").fit(\n",
    "        x_train, y_train\n",
    "    )\n",
    "    y_pred = dt_model.predict(x_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(\n",
    "        y_test, y_pred, average=None, labels=used_activities\n",
    "    )\n",
    "    recall = metrics.recall_score(y_test, y_pred, average=None, labels=used_activities)\n",
    "\n",
    "    print(\"Accuracy: \", acc, \"\\n\", \"Precision: \", precision, \"\\n\", \"Recall: \", recall)\n",
    "\n",
    "    with open(\"dt_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dt_model, f)\n",
    "\n",
    "    dt_cm = confusion_matrix(y_test, y_pred, labels=used_activities)\n",
    "    print(\"Confusion Matrix: \\n\", dt_cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(70, 7))\n",
    "\n",
    "    tree.plot_tree(\n",
    "        dt_model,\n",
    "        feature_names=feature_names,\n",
    "        fontsize=7,\n",
    "        class_names=used_activities,\n",
    "        filled=True,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    plt.savefig(\"_\".join(used_activities) + \".jpg\", dpi=600)\n",
    "\n",
    "    plt.close()  # Prevent the plot from showing in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Interpretation of the results**: What do these accuracy scores suggest about the ability of the model to distinguish between these activities? Do some activities appear to be more distinguishable than others? How do different combinations of activities affect the accuracy? Remember to provide a brief discussion for each point. \n",
    "\n",
    "Classifying the three different types of walking was reasonably accurate with ~70% accuracy. Intuitively, walking faster will be more irregular. Therefore, we would expect the standard deviation of the signal to be greater. This is exactly what the decision tree is looking for in the root node.\n",
    "\n",
    "Classification of walking up and down stairs had the highest accuracy of almost 90%. Intuitively, walking upstairs usually involves softer steps, whereas walking downstairs involves harder steps that must counteract the momentum generated from gravity. Examining the decision tree, we notice that the root decides based on the minimum acceleration. Following the intuition, the amplitude of the acceleration signal will be greater for walking downstairs rather than upstairs, so it makes sense that the greatest information gain involves the min/max of acceleration. This difference likely leads to the high accuracy of this classification.\n",
    "\n",
    "The static activities were classified with similar accuracy to the three different types of walking. Intuitively, standing will have more motion than sitting or lying down. Therefore, the root node checks the standard deviation, like the walking classifier.\n",
    "\n",
    "Considering the first three training sets, it seems that it is easiest to distinguish the walking up and down stairs than walking at different speeds or between stationary activities.\n",
    "\n",
    "Classifying the mobile activities had the lowest accuracy. This classifier had the challenge of classifying six activities (second only to classifying all of the activities). Examining the leaves of the decision tree, several of them have many samples with a large entropy. It is possible that the tree was limited by the maximum depth. The accuracy may be improved by using a greater maximum depth. For this classifier, it may be preferrable to use minimum leaf nodes instead of maximum depth to prevent overfitting.\n",
    "\n",
    "Classifying all activities leads to similar issues with classifying all of the mobile activities. Comparing this to training on all of the mobile activities, the increased in accuracy (60% vs 65%) in the former suggests that it is easier to distinguish activities with motion from stationary motions. \n",
    "\n",
    "If  there are too many activities to classify, then the decision tree will struggle due to its limited depth. This is evidenced by how the classification for three or less activities (walking, stairs, and static) had accuracies of >70%, whereas classifying mobile and all activities had accuracies of 60% and 65%, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23bdf6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lying']\n"
     ]
    }
   ],
   "source": [
    "test_live_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052a6fb-a72b-49e3-ac89-704ce3ee1769",
   "metadata": {},
   "source": [
    "# Live Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611a0fd5-a451-421a-a0f5-d8e5a75649ea",
   "metadata": {},
   "source": [
    "link: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://drive.google.com/file/d/1xEKujxMv5Vq9XRNLQ2QNZ3B9cwI1UXQj/view?usp=sharing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 389.190769,
   "end_time": "2022-07-26T08:46:55.211994",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-26T08:40:26.021225",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
